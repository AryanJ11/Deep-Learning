{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\ARYAN JAIN\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\ARYAN JAIN\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "data=keras.datasets.imdb\n",
    "(train_data,train_labels),(test_data,test_labels)=data.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=data.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index={k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"]=0\n",
    "word_index[\"<START>\"]=1\n",
    "word_index[\"<UNK>\"]=2\n",
    "word_index[\"<UNUSED>\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index=dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "train_data=keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"],padding=\"post\", maxlen=250)\n",
    "test_data=keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"],padding=\"post\", maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i,\"?\") for i in text])\n",
    "\n",
    "print(decode_review(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.Sequential([\n",
    "    keras.layers.Embedding(10000,16),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data=train_data[:10000]\n",
    "validation_label=train_labels[:10000]\n",
    "x_train=train_data[10000:]\n",
    "y_train=train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6928 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5444\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.6902 - accuracy: 0.6406 - val_loss: 0.6877 - val_accuracy: 0.6664\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.6821 - accuracy: 0.7297 - val_loss: 0.6759 - val_accuracy: 0.7408\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.6629 - accuracy: 0.7663 - val_loss: 0.6513 - val_accuracy: 0.7679\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.6300 - accuracy: 0.7891 - val_loss: 0.6147 - val_accuracy: 0.7827\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5846 - accuracy: 0.8073 - val_loss: 0.5686 - val_accuracy: 0.7973\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5316 - accuracy: 0.8262 - val_loss: 0.5200 - val_accuracy: 0.8145\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.4786 - accuracy: 0.8451 - val_loss: 0.4736 - val_accuracy: 0.8326\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.4297 - accuracy: 0.8611 - val_loss: 0.4342 - val_accuracy: 0.8422\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3890 - accuracy: 0.8709 - val_loss: 0.4018 - val_accuracy: 0.8524\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.3546 - accuracy: 0.8824 - val_loss: 0.3768 - val_accuracy: 0.8580\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.3264 - accuracy: 0.8913 - val_loss: 0.3568 - val_accuracy: 0.8650\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3032 - accuracy: 0.8965 - val_loss: 0.3416 - val_accuracy: 0.8691\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2840 - accuracy: 0.9028 - val_loss: 0.3293 - val_accuracy: 0.8721\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2671 - accuracy: 0.9061 - val_loss: 0.3193 - val_accuracy: 0.8759\n"
     ]
    }
   ],
   "source": [
    "fitmodel=model.fit(x_train,y_train,epochs=15,batch_size=512,validation_data=(valid_data,validation_label),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3303 - accuracy: 0.8673\n",
      "[0.3303338587284088, 0.8672800064086914]\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(test_data,test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king irritated <UNK> sends them a <UNK> br br delighted with this <UNK> looking new king who towers above them the <UNK> welcome him with a <UNK> of <UNK> dressed <UNK> the mayor steps forward to hand him the key to the <UNK> as <UNK> cameras record the event to everyone's horror the <UNK> promptly eats the mayor and then goes on a merry rampage <UNK> citizens at random a title card <UNK> reads news of the king's <UNK> throughout the kingdom when the now terrified <UNK> once more <UNK> <UNK> for help he loses his temper and <UNK> their community with lightning <UNK> the moral of our story delivered by a hapless frog just before he is eaten is let well enough alone br br considering the time period when this startling little film was made and considering the fact that it was made by a russian <UNK> at the height of that <UNK> country's civil war it would be easy to see this as a <UNK> about those events <UNK> may or may not have had <UNK> turmoil in mind when he made <UNK> but whatever <UNK> his choice of material the film stands as a <UNK> tale of universal <UNK> <UNK> could be the soviet union italy germany or japan in the 1930s or any country of any era that lets its guard down and is overwhelmed by <UNK> it's a fascinating film even a charming one in its macabre way but its message is no joke\n",
      "Predicted: [0.0910868]\n",
      "Actual: 1\n"
     ]
    }
   ],
   "source": [
    "review=test_data[2]\n",
    "rate=test_labels[2]\n",
    "pred=model.predict([review])\n",
    "\n",
    "print(decode_review(review))\n",
    "print(\"Predicted: {}\".format(pred[0]))\n",
    "print(\"Actual: {}\".format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
